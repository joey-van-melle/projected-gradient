---
title: "Rapport de laboratoire 6"
subtitle: "MTH8408"
author:
  - name: Joey Van Melle
    email: joey.van-melle@polymtl.ca
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:
    keep-tex: false
    documentclass: article
    include-in-header:
      - text: |
            \usepackage{eulervm}
            \usepackage{xspace}
            \usepackage[francais]{babel}
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
engine: julia
---

```{julia}
#| output: false
VERSION == v"1.11.5" || error("please use julia version 1.11.5")
using Pkg
Pkg.activate("labo11_env")
Pkg.add("OptimizationProblems")
Pkg.add("Plots")
Pkg.add("NLPModels")
Pkg.add("ADNLPModels")
Pkg.add("SolverCore")
Pkg.add("NLPModelsIpopt")
Pkg.add("Ipopt")

```

# Question 1

Implémenter la condition d'Armijo modifiée et la méthode du gradient projeté tel que demandé dans le laboratoire.
Votre implémentation doit accepter des contraintes définies par un ensemble "simple" $C$.

```{julia}
# votre code ici
using LinearAlgebra
using NLPModels
using ADNLPModels
using SolverCore


abstract type AbstractSimpleSet end;

mutable struct SimpleBounds{V} <: AbstractSimpleSet where V <: AbstractVector
  ℓ::V  # vector of lower bounds
  u::V  # vector of upper bounds
end

function SimpleBounds(model::AbstractNLPModel{T, V}) where {T, V}
  ℓ = model.meta.lvar
  u = model.meta.uvar
  SimpleBounds{V}(ℓ, u)
end

function projection!(x::V, C::SimpleBounds{V}) where V <: AbstractVector
  ℓ = C.ℓ
  u = C.u
  x .= min.(max.(x, ℓ), u)
  x
end

function armijo(model::AbstractNLPModel{T,V}, C::AbstractSimpleSet, fvalue::Float64, x::V, gx::V) where {T, V}
  α = 1.0
  y = projection!(x - α*gx, C)
  p = y - x
  while (obj(model, y) > fvalue + 1e-4* gx'p)
    α *= 0.5
    y = projection!(x - α*gx, C)
    p = y - x
  end
  return α, p
end

function projected_gradient_norm(x, gx, C)
    y = copy(x)
    projection!(y .= x .- gx, C)
    return norm(x - y)
end


function projected_gradient(model::AbstractNLPModel{T,V}, C::AbstractSimpleSet; ϵa::T = eps(T)^(1/3), ϵr::T = eps(T)^(1/3), 
                      max_eval :: Int = 1_000, 
                      max_time :: AbstractFloat = 60.,
                      max_iter :: Int = typemax(Int64)) where {T, V}
    iter = 0 
    el_time = 0.0
    tired   = neval_cons(model) > max_eval || el_time > max_time
    status  = :unknown

    start_time = time()

    x0 = copy(model.meta.x0)
    x = copy(x0)
    fvalue = obj(model, x)
    g_0 = grad(model, x0)
    gx = copy(g_0)
    g0norm = projected_gradient_norm(x0, g_0, C)
    gnorm = projected_gradient_norm(x, gx, C)
    α, p = armijo(model, C, fvalue, x, gx)
    pnorm = norm(p)
    optimal   =  gnorm <= ϵa + ϵr* g0norm

    @info log_header([:iter, :nf, :primal, :nd, :Δ],
    [Int, Int, Float64, String, Float64, Float64],
    hdr_override=Dict(:nf => "#F", :primal => "f(x)", :nd => "‖d‖", :Δ => "‖Δf‖"))

    @info log_row(Any[iter, neval_obj(model), fvalue, pnorm, gnorm])

    while !(optimal || tired)

        x += p
        fvalue = obj(model, x)
        gx = grad(model, x)
        gnorm = projected_gradient_norm(x, gx, C)
        α, p = armijo(model, C, fvalue, x, gx)
        pnorm = norm(p)
        optimal   =  gnorm <= ϵa + ϵr* g0norm

        el_time      = time() - start_time
        iter        += 1
        many_evals   = neval_obj(model) > max_eval
        iter_limit   = iter > max_iter
        tired        = many_evals || el_time > max_time || iter_limit

        @info log_row(Any[iter, neval_obj(model), fvalue, pnorm, gnorm])

    end

    status = if optimal 
        :first_order
    elseif tired
        if neval_obj(model) > max_eval
            :max_eval
        elseif el_time > max_time
            :max_time
        elseif iter > max_iter
            :max_iter
        else
            :unknown
        end
    else
        :unknown
    end

    println("nb iterations : $iter")

    return GenericExecutionStats(model; status=status, solution = x,
                                 objective = obj(model, x),
                                 primal_feas = NaN,
                                 dual_feas = NaN,
                                 elapsed_time = el_time,
                                 solver_specific=Dict(:iter => iter))
end

```

# Question 2

Tester votre implémentation et comparer la solution finale à celle de IPOPT sur 3 problèmes tirés de `OptimizationProblems`.

```{julia}
using OptimizationProblems
using OptimizationProblems.ADNLPProblems
using Ipopt
using NLPModelsIpopt

problems = ["hs38", "hs242", "hs38"]
output = Dict()

for pb_name in problems
  
  model = getfield(OptimizationProblems.ADNLPProblems, Symbol(pb_name))()

  C = SimpleBounds(model)

  println(pb_name)
  stats = projected_gradient(model, C)
  output[(pb_name, "gp")] = stats

  println("IPOPT")
  stats2 = ipopt(model, options=Dict("print_level"=>0))
  output[(pb_name, "IPOPT")] = stats2
end

for pb_name in problems
    println(pb_name)
    stats = output[(pb_name, "gp")]
    stats2 = output[(pb_name, "IPOPT")]

    println("###########################################")
    println("GP")
    print(stats)
    println("-----------------------------------")
    println("IPOPT")
    print(stats2)
end
```

Dans les trois cas, on arrive à convergé mais la solution n'est pas aussi bonne que Ipopt de plusieurs degrés de magnitures.


# Questions 3

Implémenter une structure et la fonction de projection pour une boule euclidienne.

```{julia}
mutable struct SimpleBall{V} <: AbstractSimpleSet where V <: AbstractVector
  r::Float64  # radius of the ball
  center::V  # center of the ball
end

function projection!(x::V, C::SimpleBall{V}) where V <: AbstractVector
  r = C.r
  center = C.center
  v = x .- center
  nv = norm(v)
  if nv <= r
        return x 
    else
        x .= center .+ v .* (r / nv)
        return x
    end
end

```

# Question 4

Minimiser une quadratique non convexe à $n = 10$ variables sur une boule euclidienne centrée à l'origine à la manière d'un sous-problème de région de confiance.
Votre solution pourrait-elle être utilisée pour calculer un pas dans une méthode de région de confiance ?
Expliquer.

```{julia}
using LinearAlgebra, Random
using ADNLPModels

n = 10
Random.seed!(123)

d = [(-1)^i * rand() * 10 for i in 1:n]
Q = Diagonal(d)
b = randn(n)

f(x) = x' * Q * x + b' * x

x0 = zeros(n)

lvar = -Inf * ones(n)
uvar = Inf * ones(n)

model = ADNLPModel(f, x0, lvar, uvar)

C = SimpleBall(1.0, x0)

stats = projected_gradient(model, C)

println(stats)

```

# Votre solution pourrait-elle être utilisée pour calculer un pas dans une méthode de région de confiance ? 
Oui en fait, elle retourne exactement s. Le problème de cette méthode c'est qu'elle n'est pas optimale en ce sens où elle aura de la
difficulté à prendre une direction optimale lorsque le problème n'est pas convexe. Ainsi, la méthode peut être lente.
